{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer learning from ImageNet on ResNet\n",
    "#https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "#https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "#https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "#https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "#https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()\n",
    "\n",
    "\n",
    "\n",
    "import torch.utils.data\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self.data = torch.tensor(x, requires_grad=True)\n",
    "        self.label = torch.tensor(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of data point we have. Alternatively self.data.shape[0], or self.label.shape[0]\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return the idx-th data point of the dataset\n",
    "        # If we have multiple things to return (data point and label), we can return them as tuple\n",
    "        data_point = self.data[idx]\n",
    "        data_label = self.label[idx]\n",
    "        return data_point, data_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load numpy dataset from data/schizzi with numpy\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "data = np.array([])\n",
    "labels = np.array([])\n",
    "\n",
    "count = 0\n",
    "data_dir = 'data/schizzi'\n",
    "#iterate over all files in data_dir\n",
    "for filename in os.listdir(data_dir):\n",
    "    f = os.path.join(data_dir, filename)\n",
    "    \n",
    "    x = np.load(f)\n",
    "    x = x[:100]\n",
    "    x = x.reshape(-1, 28, 28)\n",
    "\n",
    "    y = count * np.ones(len(x))\n",
    "\n",
    "    #repeat x on 3 channels\n",
    "    x = np.stack((x,)*3, axis=1)\n",
    "\n",
    "    if count == 0:\n",
    "        data = x\n",
    "        labels = y\n",
    "    else:\n",
    "        data = np.concatenate((data, x), axis=0)\n",
    "        labels = np.concatenate((labels, y), axis=0)\n",
    "\n",
    "    count += 1\n",
    "    if count == 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(data.astype(np.float32), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate mean and std\n",
    "DATA_MEANS = (dataset.data / 255.0).mean(axis=(0,1,2))\n",
    "DATA_STD = (dataset.data / 255.0).std(axis=(0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Function for setting the seed\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(DATA_MEANS, DATA_STD)\n",
    "])\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #use GPU if available\n",
    "\n",
    "#split dataset into train, validation and test\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_loader))[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, count)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, criterion, optimizer, max_epochs=50):\n",
    "        \n",
    "    results = None\n",
    "    val_scores = []\n",
    "    train_losses, train_scores = [], []\n",
    "    best_val_epoch = -1\n",
    "    net = net.double()\n",
    "    for epoch in range(max_epochs):\n",
    "        ############\n",
    "        # Training #\n",
    "        ############\n",
    "        net.train()\n",
    "        true_preds, count = 0., 0\n",
    "        i = 0\n",
    "        for imgs, labels in train_loader:\n",
    "            print(f\"Batch {i}/{len(train_loader)}\")\n",
    "            i += 1\n",
    "            imgs = imgs.double()\n",
    "            labels = labels.long()\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = net(imgs)\n",
    "            #softmax\n",
    "            preds = torch.functional.F.softmax(preds, dim=-1)\n",
    "            loss = criterion(preds, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Record statistics during training\n",
    "            true_preds += (preds.argmax(dim=-1) == labels).sum().item()\n",
    "            count += labels.shape[0]\n",
    "            train_losses.append(loss.item())\n",
    "        train_acc = true_preds / count\n",
    "        train_scores.append(train_acc)\n",
    "\n",
    "        ##############\n",
    "        # Validation #\n",
    "        ##############\n",
    "        val_acc = test_model(net, val_loader)\n",
    "        val_scores.append(val_acc)\n",
    "        print(f\"[Epoch {epoch+1:2d}] Training accuracy: {train_acc*100.0:05.2f}%, Validation accuracy: {val_acc*100.0:05.2f}%\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(net, data_loader):\n",
    "    net.eval()\n",
    "    true_preds, count = 0., 0\n",
    "    for imgs, labels in data_loader:\n",
    "        imgs = imgs.double()\n",
    "        labels = labels.long()\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = net(imgs)\n",
    "            #softmax\n",
    "            preds = torch.functional.F.softmax(preds, dim=-1)\n",
    "            preds = preds.argmax(dim=-1)\n",
    "            true_preds += (preds == labels).sum().item()\n",
    "            count += labels.shape[0]\n",
    "    test_acc = true_preds / count\n",
    "    return test_acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/4\n",
      "Batch 1/4\n",
      "Batch 2/4\n",
      "Batch 3/4\n",
      "[Epoch  1] Training accuracy: 18.25%, Validation accuracy: 22.00%\n",
      "Batch 0/4\n",
      "Batch 1/4\n",
      "Batch 2/4\n",
      "Batch 3/4\n",
      "[Epoch  2] Training accuracy: 15.75%, Validation accuracy: 18.00%\n",
      "Batch 0/4\n",
      "Batch 1/4\n",
      "Batch 2/4\n",
      "Batch 3/4\n",
      "[Epoch  3] Training accuracy: 17.00%, Validation accuracy: 16.00%\n",
      "Batch 0/4\n",
      "Batch 1/4\n",
      "Batch 2/4\n",
      "Batch 3/4\n",
      "[Epoch  4] Training accuracy: 19.00%, Validation accuracy: 30.00%\n",
      "Batch 0/4\n",
      "Batch 1/4\n",
      "Batch 2/4\n",
      "Batch 3/4\n",
      "[Epoch  5] Training accuracy: 19.75%, Validation accuracy: 28.00%\n"
     ]
    }
   ],
   "source": [
    "return_val = train_model(model_conv, criterion, optimizer_conv, max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model\n",
    "test_acc = test_model(model_conv.double(), test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Test accuracy: 0.14\n"
     ]
    }
   ],
   "source": [
    "#print len of test_loader\n",
    "print(len(test_dataset))\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
